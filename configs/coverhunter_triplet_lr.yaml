MODEL :
  NAME: berlin
  # Model
  ARCHITECTURE: coverhunter
  EMBEDDING_SIZE: 512
  # ATTENTION_DIM: 256 
  # NUM_BLOCKS = 6
  # OUTPUT_DIM = 128
  OUTPUT_CLS: null # not needed for triplet loss
  FREQUENCY_BINS: 84
  SAMPLE_RATE: 22050
  DOWNSAMPLE_FACTOR: 20 # might try out 3 (like CoverHunter)
  L2_NORMALIZE: True # L2 normalize the embeddings.
  SIMILARITY_SEARCH: MIPS # ['MCSS', 'NNS', 'MIPS'] If L2_NORMALIZE is True, use 'MIPS' for faster search.
  CHECKPOINT_DIR: logs/checkpoints/
  # CONV_CHANNEL: 40
  # NORMALIZATION: bn # ['bn', 'in', 'ibn']
  # POOLING: adaptive_max # ['adaptive_max', 'gem', 'softpool']
  # PROJECTION: linear # ['none', 'linear', 'affine', 'mlp']

TRAIN:
    # Train and Validation, and Augmentation directories
    FEATURES_DIR: /data/audio/cqt/
    TRAIN_CLIQUES: /data/discogs/Discogs-VI-YT-20240701-light.json.train
    VALIDATION_CLIQUES: /data/discogs/Discogs-VI-YT-20240701-light.json.val
    M_PER_CLASS: 8 # Number of versions per clique during a training iteration.
    CONTEXT_LENGTH: 7600 # Number of frames to consider as context, before downsampling.
    BATCH_SIZE: 256 # Number of versions in batch.
    EPOCHS: 40 # Number of epochs to train.
    LOSS:
      TRIPLET:
        MARGIN: 0.3 # Triplet loss margin
        POSITIVE_MINING: random # ['hard', 'random', 'easy']
        NEGATIVE_MINING: hard # ['hard', 'random', 'semi-hard']        SQUARED_DISTANCE: False # Use squared distance in the loss.
        NON_ZERO_MEAN: True # If true, the zero losses in the batch are filtered out before averaging.
    OPTIMIZER: Adam # ['Adam', 'AdamW']
    AUTOMATIC_MIXED_PRECISION: False # Use mixed precision training.
    LR:
      SCHEDULE: NONE # ['NONE', 'STEP', 'MULTISTEP', 'EXPONENTIAL', 'COSINE, LIN-WARMUP-PCWS'].
      LR: 0.1 # Starting learning rate in case of a schedule or constant in case of NONE.
    CUDA_DETERMINISTIC: False # Set to True for deterministic training.
    CUDA_BENCHMARK: False # Set to True for benchmarking.
    CLIQUE_USAGE_RATIO: 1.0 # Fraction of training data to use. Useful for debugging. 1.0 to use 100% of data.