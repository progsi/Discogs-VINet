MODEL :
  NAME: Discogs-VINet
  ARCHITECTURE: cqtnet
  CONV_CHANNEL: 40
  EMBEDDING_SIZE: 512
  NORMALIZATION: bn # ['bn', 'in', 'ibn']
  POOLING: adaptive_max # ['adaptive_max', 'gem', 'softpool']
  NECK: linear # ['none', 'linear', 'affine', 'mlp']
  L2_NORMALIZE: True # L2 normalize the embeddings.
  SIMILARITY_SEARCH: MIPS # ['MCSS', 'NNS', 'MIPS'] If L2_NORMALIZE is True, use 'MIPS' for faster search.
  DOWNSAMPLE_FACTOR: 20 # Downsampling factor.
  CHECKPOINT_DIR: logs/checkpoints/

TRAIN:
  # Train and Validation, and Augmentation directories
  FEATURES_DIR: /data/audio/cqt/
  TRAIN_CLIQUES: /data/discogs/Discogs-VI-YT-20240701-light.json.train
  VALIDATION_CLIQUES: /data/discogs/Discogs-VI-YT-20240701-light.json.val
  M_PER_CLASS: 2 # Number of versions per clique during a training iteration.
  SCALE: normalize # ['normalize', 'upscale']
  MAX_LENGTH: 7600 # Number of frames to consider as context, before downsampling.
  BATCH_SIZE: 96 # Number of versions in batch.
  EPOCHS: 50 # Number of epochs to train.
  LOSS:
    TRIPLET:
      MARGIN: 0.3 # Triplet loss margin
      POSITIVE_MINING: random # ['hard', 'random', 'easy']
      NEGATIVE_MINING: hard # ['hard', 'random', 'semi-hard']
      SQUARED_DISTANCE: False # Use squared distance in the loss.
      NON_ZERO_MEAN: True # If true, the zero losses in the batch are filtered out before averaging.
  OPTIMIZER: Adam # ['Adam', 'AdamW']
  AUTOMATIC_MIXED_PRECISION: True # Use mixed precision training.
  LR:
    SCHEDULE: EXPONENTIAL-MIN_LR # ['NONE', 'STEP', 'MULTISTEP', 'EXPONENTIAL' 'EXPONENTIAL-MIN_LR', 'COSINE, LIN-WARMUP-PCWS'].
    LR: 0.001 
    PARAMS:
      ETA_MIN: 0.0001 # from 
      GAMMA: 0.9975
  CUDA_DETERMINISTIC: False # Set to True for deterministic training.
  CUDA_BENCHMARK: False # Set to True for benchmarking.
  CLIQUE_USAGE_RATIO: 1.0 # Fraction of training data to use. Useful for debugging. 1.0 to use 100% of data.